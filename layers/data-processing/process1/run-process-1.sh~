#!/bin/sh

# Usuwamy timestamp i laczymy pliki ktore zostaly rozdzielone przez flume
hdfs dfs -text New_batch_data/lap_times* | hdfs dfs -put - New_batch_data/lap_times.csv
hdfs dfs -rm New_batch_data/lap_times.csv.*
hdfs dfs -text New_batch_data/circuits* | hdfs dfs -put - New_batch_data/circuits.csv
hdfs dfs -rm New_batch_data/circuits.csv.*
hdfs dfs -text New_batch_data/constructors* | hdfs dfs -put - New_batch_data/constructors.csv
hdfs dfs -rm New_batch_data/constructors.csv.*
hdfs dfs -text New_batch_data/races* | hdfs dfs -put - New_batch_data/races.csv
hdfs dfs -rm New_batch_data/races.csv.*
hdfs dfs -text New_batch_data/results* | hdfs dfs -put - New_batch_data/results.csv
hdfs dfs -rm New_batch_data/results.csv.*
hdfs dfs -text New_batch_data/status* | hdfs dfs -put - New_batch_data/status.csv
hdfs dfs -rm New_batch_data/status.csv.*
hdfs dfs -text New_batch_data/driver* | hdfs dfs -put - New_batch_data/driver.csv
hdfs dfs -rm New_batch_data/driver.csv.*

echo "Step 1: processing status.csv"
spark-submit --class Test --master local process1/statusTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/status.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/status 

echo "Step 2: processing drivers.csv"
spark-submit --class Test --master local process1/driverTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/driver.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/drivers 

echo "Step 3: processing circuits.csv"
spark-submit --class Test --master local process1/circuitsTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/circuits.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/circuits 

echo "Step 4: processing constructors.csv"
spark-submit --class Test --master local process1/constructorsTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/constructors.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/constructors 

echo "Step 5: processing lap_times.csv"
spark-submit --class Test --master local process1/lapTimesTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/lap_times.csv hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/races.csv hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/driver.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/lap_times 

echo "Step 6: processing races.csv"
spark-submit --class Test --master local process1/racesTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/races.csv hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/circuits.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/races

echo "Step 7: processing results.csv"
spark-submit --class Test --master local process1/resultsTransform.jar hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/results.csv hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/races.csv hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/driver.csv hdfs://quickstart.cloudera:8020/user/cloudera/New_batch_data/constructors.csv hdfs://quickstart.cloudera:8020/user/cloudera/Data_source/results 

# Ustrukturyzowanie wynikow przetwarzania 1 
hdfs dfs -text Data_source/status/part* | hdfs dfs -put - Data_source/status.csv
hdfs dfs -rm -r Data_source/status
hdfs dfs -text Data_source/drivers/part* | hdfs dfs -put - Data_source/driver.csv
hdfs dfs -rm -r Data_source/drivers
hdfs dfs -text Data_source/circuits/part* | hdfs dfs -put - Data_source/circuits.csv
hdfs dfs -rm -r Data_source/circuits
hdfs dfs -text Data_source/constructors/part* | hdfs dfs -put - Data_source/constructors.csv
hdfs dfs -rm -r Data_source/constructors
hdfs dfs -text Data_source/lap_times/part* | hdfs dfs -put - Data_source/lap_times.csv
hdfs dfs -rm -r Data_source/lap_times
hdfs dfs -text Data_source/races/part* | hdfs dfs -put - Data_source/races.csv
hdfs dfs -rm -r Data_source/races
hdfs dfs -text Data_source/results/part* | hdfs dfs -put - Data_source/results.csv
hdfs dfs -rm -r Data_source/results

